{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8964b3",
   "metadata": {},
   "source": [
    "#### Login to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ac66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"YOUR_HUGGINGFACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa52aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd022be5",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b33572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# MODEL_ID = \"google/gemma-2b-it\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_ID,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     device_map=\"auto\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85863614",
   "metadata": {},
   "source": [
    "#### Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1990a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2b-it\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gemma-lora-webq-finetuned\")\n",
    "\n",
    "model = PeftModel.from_pretrained(base, \"gemma-lora-webq-finetuned\")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd10811",
   "metadata": {},
   "source": [
    "#### Load Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec67e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"knowledge_graph.csv\")\n",
    "\n",
    "filtered_df = df[[\"subject_label\", \"predicate_label\", \"object_label\"]].copy()\n",
    "\n",
    "filtered_df['subject_label'] = filtered_df['subject_label'].astype(str).str.strip()\n",
    "filtered_df['predicate_label'] = filtered_df['predicate_label'].astype(str).str.strip()\n",
    "filtered_df['object_label'] = filtered_df['object_label'].astype(str).str.strip()\n",
    "\n",
    "filtered_df['subject_label_lower'] = filtered_df['subject_label'].str.lower()\n",
    "filtered_df['predicate_label_lower'] = filtered_df['predicate_label'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a505915",
   "metadata": {},
   "source": [
    "#### Grab Unique Subjects & Predicts From Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44785546",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = filtered_df['subject_label_lower'].unique()\n",
    "predicate_list = filtered_df['predicate_label_lower'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955ba473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load a lightweight embedding model\n",
    "embedder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "filtered_df[\"triple_text\"] = (\n",
    "    filtered_df[\"subject_label\"] + \" | \"\n",
    "    + filtered_df[\"predicate_label\"] + \" | \"\n",
    "    + filtered_df[\"object_label\"]\n",
    ")\n",
    "\n",
    "triples = filtered_df[\"triple_text\"].tolist()\n",
    "\n",
    "# Precompute embeddings once\n",
    "triple_embeddings = embedder.encode(\n",
    "    triples, convert_to_tensor=True, show_progress_bar=True, normalize_embeddings= True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4f304",
   "metadata": {},
   "source": [
    "#### Semantic search (Cosine Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31118e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_facts(question, triples, triple_embeddings, top_k=3):\n",
    "    \n",
    "    q_emb = embedder.encode(question, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    cos_scores = util.cos_sim(q_emb, triple_embeddings)[0]\n",
    "    top_idxs = torch.topk(cos_scores, k=top_k).indices.tolist()\n",
    "    return [triples[i] for i in top_idxs]\n",
    "\n",
    "def get_facts_for_question(question):\n",
    "    try:\n",
    "        return get_semantic_facts(question, triples, triple_embeddings, top_k=5)\n",
    "    except Exception:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd0bbe",
   "metadata": {},
   "source": [
    "#### Extract Facts from Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import difflib\n",
    "\n",
    "# def extract_best_match(text, candidates, cutoff=0.6):\n",
    "#     text = text.lower()\n",
    "\n",
    "#     best_matches = difflib.get_close_matches(text, candidates, n=1, cutoff=cutoff)\n",
    "#     if best_matches:\n",
    "#         return best_matches[0]\n",
    "    \n",
    "#     matches = [c for c in candidates if c in text]\n",
    "#     return max(matches, key=len) if matches else None\n",
    "\n",
    "# def get_facts_for_question(question, df, subject_list, predicate_list):\n",
    "\n",
    "#     matched_subject = extract_best_match(question, subject_list)\n",
    "#     if matched_subject is None:\n",
    "#         return []\n",
    "\n",
    "#     subject_df = df[df[\"subject_label_lower\"] == matched_subject]\n",
    "#     if subject_df.empty:\n",
    "#         return []\n",
    "\n",
    "#     matched_predicate = extract_best_match(question, predicate_list)\n",
    "\n",
    "#     if matched_predicate:\n",
    "\n",
    "#         filtered_df = subject_df[\n",
    "#             subject_df[\"predicate_label\"].str.lower() == matched_predicate\n",
    "#         ]\n",
    "#         if not filtered_df.empty:\n",
    "#             facts = [\n",
    "#                 f\"{row['subject_label']} — {row['predicate_label']} — {row['object_label']}\"\n",
    "#                 for _, row in filtered_df.iterrows()\n",
    "#             ]\n",
    "#             return facts\n",
    "\n",
    "#     facts = [\n",
    "#         f\"{row['subject_label']} — {row['predicate_label']} — {row['object_label']}\"\n",
    "#         for _, row in subject_df.iterrows()\n",
    "#     ]\n",
    "#     return facts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a51b2",
   "metadata": {},
   "source": [
    "#### Generate Answer using facts from Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb45867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question, facts):\n",
    "    formatted_facts = \"\\n\".join(f\"- {fact}\" for fact in facts)\n",
    "    prompt = f\"\"\"<bos>\n",
    "[INST]\n",
    "Using the facts below, answer the question with a short, direct answer.\n",
    "\n",
    "Facts:\n",
    "{formatted_facts}\n",
    "\n",
    "Question: {question}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=False\n",
    "    )\n",
    "    \n",
    "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    if \"[/INST]\" in full_output:\n",
    "        answer_only = full_output.split(\"[/INST]\")[-1].strip()\n",
    "    else:\n",
    "        answer_only = full_output.strip()\n",
    "\n",
    "    return answer_only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb9bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"what state does selena gomez?\"\n",
    "\n",
    "# facts = get_facts_for_question(question, filtered_df, subject_list, predicate_list)\n",
    "\n",
    "# answer = generate_answer(question, facts)\n",
    "\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c31c6",
   "metadata": {},
   "source": [
    "#### Questions from Webquestions Dataset (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d6005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"stanfordnlp/web_questions\", split=\"test\")\n",
    "\n",
    "full = load_dataset(\"stanfordnlp/web_questions\")\n",
    "full = full.filter(lambda ex: len(ex[\"answers\"]) > 0)\n",
    "split = full[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "raw_train, raw_test = split[\"train\"], split[\"test\"]\n",
    "\n",
    "questions_df = pd.DataFrame(raw_test)[['question', 'answers']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a06121e",
   "metadata": {},
   "source": [
    "#### Process One Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c276ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_question(question):\n",
    "    # facts = get_facts_for_question(question, filtered_df, subject_list, predicate_list)\n",
    "    facts = get_facts_for_question(question)\n",
    "    \n",
    "    if not facts:\n",
    "        facts = [\"No facts available.\"]\n",
    "    return generate_answer(question, facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb358b8",
   "metadata": {},
   "source": [
    "#### Answer all questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9109930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "questions_df['predicted_answer'] = questions_df['question'].progress_apply(process_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866d329",
   "metadata": {},
   "source": [
    "#### Prepare Data for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "references_bleu = questions_df['answers'].tolist()\n",
    "references_rouge = questions_df['answers'].apply(lambda x: ' / '.join(x)).tolist()\n",
    "\n",
    "predictions = questions_df['predicted_answer'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7f07c6",
   "metadata": {},
   "source": [
    "#### Evaluate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13444c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "bleu_res = bleu.compute(predictions=predictions, references=references_bleu)\n",
    "rouge_res = rouge.compute(predictions=predictions, references=references_rouge)\n",
    "\n",
    "results_df = pd.DataFrame([{\n",
    "    \"bleu\":      bleu_res[\"bleu\"],\n",
    "    \"rouge1\":    rouge_res[\"rouge1\"],\n",
    "    \"rouge2\":    rouge_res[\"rouge2\"],\n",
    "    \"rougeL\":    rouge_res[\"rougeL\"],\n",
    "    \"rougeLsum\": rouge_res[\"rougeLsum\"],\n",
    "}])\n",
    "\n",
    "results_df.to_csv(\"evaluation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b5912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
