{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89567690",
   "metadata": {},
   "source": [
    "#### Load WebQuestions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"stanfordnlp/web_questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f52f0",
   "metadata": {},
   "source": [
    "#### Convert dataset to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def to_dataframe(split):\n",
    "    return pd.DataFrame({\n",
    "        \"question\": [ex[\"question\"] for ex in split],\n",
    "        \"answers\": [ex[\"answers\"] for ex in split],\n",
    "        \"fb_url\": [ex[\"url\"] for ex in split]\n",
    "    })\n",
    "\n",
    "df_train = to_dataframe(dataset[\"train\"])\n",
    "df_test = to_dataframe(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466fa31a",
   "metadata": {},
   "source": [
    "#### Grab freebase name from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4628b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"freebase_name\"] = df_train[\"fb_url\"].apply(lambda x: x.split(\"/\")[-1])\n",
    "df_test[\"freebase_name\"] = df_test[\"fb_url\"].apply(lambda x: x.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd5a25",
   "metadata": {},
   "source": [
    "#### Map questions to the appropriate QID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import lru_cache\n",
    "import pandas as pd\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "@lru_cache(maxsize=1000)\n",
    "def search_wikidata_qid(name):\n",
    "    \"\"\"Cached version of Wikidata search - much faster for repeated queries\"\"\"\n",
    "    url = \"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"wbsearchentities\",\n",
    "        \"search\": name,\n",
    "        \"language\": \"en\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    try:\n",
    "        response = session.get(url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        if result.get(\"search\"):\n",
    "            return result[\"search\"][0][\"id\"]\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching for '{name}': {e}\")\n",
    "        return None\n",
    "\n",
    "def search_wikidata_qid_batch(names, max_workers=10):\n",
    "    \"\"\"Process multiple names concurrently for much faster processing\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "\n",
    "        future_to_name = {executor.submit(search_wikidata_qid, name): name for name in names}\n",
    "        \n",
    "        for future in as_completed(future_to_name):\n",
    "            name = future_to_name[future]\n",
    "            try:\n",
    "                results[name] = future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing '{name}': {e}\")\n",
    "                results[name] = None\n",
    "    \n",
    "    return results\n",
    "\n",
    "df_train[\"subject_qid\"] = df_train[\"freebase_name\"].apply(search_wikidata_qid)\n",
    "df_test[\"subject_qid\"] = df_test[\"freebase_name\"].apply(search_wikidata_qid)\n",
    "\n",
    "df_train.to_parquet(\"checkpoints/train_webquestions.parquet\")\n",
    "df_test.to_parquet(\"checkpoints/test_webquestions.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe271f7",
   "metadata": {},
   "source": [
    "#### Grab all unique Q-IDs from WebQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e88d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_parquet(\"checkpoints/train_webquestions.parquet\")\n",
    "df_test = pd.read_parquet(\"checkpoints/test_webquestions.parquet\")\n",
    "\n",
    "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "subject_qids = df_all[\"subject_qid\"].dropna().unique().tolist()\n",
    "\n",
    "print(f\"Total unique subject Q-IDs: {len(subject_qids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f38ff71",
   "metadata": {},
   "source": [
    "#### Get Wikidata predicates related to QIDs from WebQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c38b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "def get_triples(qid, max_retries=5, base_delay=2):\n",
    "    query = f\"\"\"\n",
    "        SELECT ?s ?p ?propEntity ?propLabel ?o WHERE {{\n",
    "        BIND(wd:{qid} AS ?s)\n",
    "        ?s ?p ?o .\n",
    "        FILTER(STRSTARTS(STR(?p), \"http://www.wikidata.org/prop/direct/\"))\n",
    "        ?propEntity wikibase:directClaim ?p .\n",
    "        ?propEntity rdfs:label ?propLabel .\n",
    "        FILTER(LANG(?propLabel)=\"en\")\n",
    "        }}\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            sparql.setQuery(query)\n",
    "            results = sparql.query().convert()\n",
    "            triples = []\n",
    "            for r in results[\"results\"][\"bindings\"]:\n",
    "                object_uri = r.get(\"o\", {}).get(\"value\", \"\")\n",
    "                object_id = object_uri.split(\"/\")[-1] if \"wikidata.org\" in object_uri else object_uri\n",
    "\n",
    "                predicate_id = r[\"propEntity\"][\"value\"].split(\"/\")[-1]\n",
    "                predicate_label = r.get(\"propLabel\", {}).get(\"value\", predicate_id)\n",
    "\n",
    "                triples.append({\n",
    "                    \"subject_id\": qid,\n",
    "                    \"subject_label\": qid,  # placeholder\n",
    "                    \"predicate_id\": predicate_id,\n",
    "                    \"predicate_label\": predicate_label,\n",
    "                    \"object_id\": object_id,\n",
    "                    \"object_label\": object_id  # placeholder\n",
    "                })\n",
    "            return triples\n",
    "        except Exception as e:\n",
    "            if \"429\" in str(e) or \"Too Many Requests\" in str(e):\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = base_delay * (2 ** attempt) + random.uniform(0, 1)\n",
    "                    print(f\"Rate limited for {qid}, attempt {attempt + 1}/{max_retries}. Waiting {delay:.1f}s...\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Failed to get triples for {qid} after {max_retries} attempts\")\n",
    "                    return []\n",
    "            else:\n",
    "                print(f\"Error for {qid}: {e}\")\n",
    "                return []\n",
    "    return []\n",
    "\n",
    "all_triples = []\n",
    "for qid in tqdm(subject_qids):\n",
    "    triples = get_triples(qid)\n",
    "    all_triples += triples\n",
    "    time.sleep(1.0)\n",
    "\n",
    "df_triples = pd.DataFrame(all_triples)\n",
    "df_triples.to_csv(\"checkpoints/webquestions_kg_descriptive.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ed807",
   "metadata": {},
   "source": [
    "#### Labels for Subjects and Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from more_itertools import chunked\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "df_kg = pd.read_csv(\"checkpoints/webquestions_kg_descriptive.csv\")\n",
    "\n",
    "valid_qid_pattern = re.compile(r\"^Q\\d+$\")\n",
    "\n",
    "valid_ids = {qid for qid in set(df_kg['subject_id']) | set(df_kg['object_id']) if valid_qid_pattern.match(str(qid))}\n",
    "\n",
    "id_to_label = {}\n",
    "\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "def get_labels_batch(qids, max_retries=3):\n",
    "    if not qids:\n",
    "        return {}\n",
    "    qid_str = \" \".join(f\"wd:{qid}\" for qid in qids)\n",
    "    query = f\"\"\"\n",
    "    SELECT ?item ?itemLabel WHERE {{\n",
    "      VALUES ?item {{ {qid_str} }}\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            sparql.setQuery(query)\n",
    "            results = sparql.query().convert()\n",
    "            return {\n",
    "                r['item']['value'].split(\"/\")[-1]: r['itemLabel']['value']\n",
    "                for r in results[\"results\"][\"bindings\"]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            if \"429\" in str(e) or \"403\" in str(e):\n",
    "                delay = 2 ** attempt + random.random()\n",
    "                print(f\"Rate limit or forbidden (403). Retry {attempt+1}. Waiting {delay:.1f}s...\")\n",
    "                time.sleep(delay)\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Label fetch error: {e}\")\n",
    "                return {}\n",
    "\n",
    "    return {}\n",
    "\n",
    "chunks = list(chunked(valid_ids, 50))\n",
    "\n",
    "for chunk in tqdm(chunks, total=len(chunks)):\n",
    "    label_map = get_labels_batch(chunk)\n",
    "    id_to_label.update(label_map)\n",
    "    time.sleep(2.0)\n",
    "\n",
    "df_kg['subject_label'] = df_kg['subject_id'].map(id_to_label)\n",
    "df_kg['object_label'] = df_kg['object_id'].map(id_to_label)\n",
    "\n",
    "df_kg['subject_label'] = df_kg['subject_label'].fillna(df_kg['subject_id'])\n",
    "df_kg['object_label'] = df_kg['object_label'].fillna(df_kg['object_id'])\n",
    "\n",
    "df_kg.to_csv(\"checkpoints/webquestions_kg_descriptive_labeled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884e607e",
   "metadata": {},
   "source": [
    "#### Filter out Subjects, Objects and Relationships without standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b333b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph = pd.read_csv('checkpoints/webquestions_kg_descriptive_labeled.csv')\n",
    "\n",
    "condition = (knowledge_graph['subject_id'].str.match(r'^Q\\d+$', na=False) \n",
    "             & knowledge_graph['object_id'].str.match(r'^Q\\d+$', na=False)\n",
    "             & knowledge_graph['predicate_id'].str.match(r'^P\\d+$', na=False))\n",
    "\n",
    "matching = len(knowledge_graph[condition])\n",
    "non_matching = len(knowledge_graph[~condition])\n",
    "\n",
    "print(f\"Number of IDs matching pattern '^Q\\\\d+$': {matching}\")\n",
    "print(f\"Number of IDs not matching pattern '^Q\\\\d+$': {non_matching}\")\n",
    "\n",
    "knowledge_graph = knowledge_graph[condition]\n",
    "\n",
    "knowledge_graph.to_csv('checkpoints/webquestions_kg_descriptive_labeled_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfba8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
